{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "88051c3d-4a44-4ec6-8adb-c1d38653e94d",
    "_uuid": "71fff663eb9075c63db6ddd0904379ffbcdcad20"
   },
   "source": [
    "# Machine Learning Challenge\n",
    "\n",
    "## Overview\n",
    "\n",
    "The focus of this exercise is on a field within machine learning called [Natural Language Processing](https://en.wikipedia.org/wiki/Natural-language_processing). We can think of this field as the intersection between language, and machine learning. Tasks in this field include automatic translation (Google translate), intelligent personal assistants (Siri), information extraction, and speech recognition for example.\n",
    "\n",
    "NLP uses many of the same techniques as traditional data science, but also features a number of specialised skills and approaches. There is no expectation that you have any experience with NLP, however, to complete the challenge it will be useful to have the following skills:\n",
    "\n",
    "- understanding of the python programming language\n",
    "- understanding of basic machine learning concepts, i.e. supervised learning\n",
    "\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Download this notebook!\n",
    "2. Answer each of the provided questions, including your source code as cells in this notebook.\n",
    "3. Share the results with us, e.g. a Github repo.\n",
    "\n",
    "### Task description\n",
    "\n",
    "You will be performing a task known as [sentiment analysis](https://en.wikipedia.org/wiki/Sentiment_analysis). Here, the goal is to predict sentiment -- the emotional intent behind a statement -- from text. For example, the sentence: \"*This movie was terrible!\"* has a negative sentiment, whereas \"*loved this cinematic masterpiece*\" has a positive sentiment.\n",
    "\n",
    "To simplify the task, we consider sentiment binary: labels of `1` indicate a sentence has a positive sentiment, and labels of `0` indicate that the sentence has a negative sentiment.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The dataset is split across three files, representing three different sources -- Amazon, Yelp and IMDB. Your task is to build a sentiment analysis model using both the Yelp and IMDB data as your training-set, and test the performance of your model on the Amazon data.\n",
    "\n",
    "Each file can be found in the `input` directory, and contains 1000 rows of data. Each row contains a sentence, a `tab` character and then a label -- `0` or `1`. \n",
    "\n",
    "**Notes**\n",
    "- Feel free to use existing machine learning libraries as components in you solution!\n",
    "- Suggested libraries: `sklearn` (for machine learning), `pandas` (for loading/processing data), `spacy` (for text processing).\n",
    "- As mentioned, you are not expected to have previous experience with this exact task. You are free to refer to external tutorials/resources to assist you. However, you will be asked to justfify the choices you have made -- so make you understand the approach you have taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazon_cells_labelled.txt', 'imdb_labelled.txt', 'yelp_labelled.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "\n",
    "print(os.listdir(\"./input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So there is no way for me to plug it in here in the US unless I go by a converter.\t0\n",
      "Good case, Excellent value.\t1\n",
      "Great for the jawbone.\t1\n",
      "Tied to charger for conversations lasting more than 45 minutes.MAJOR PROBLEMS!!\t0\n",
      "The mic is great.\t1\n",
      "I have to jiggle the plug to get it to line up right to get decent volume.\t0\n",
      "If you have several dozen or several hundred contacts, then imagine the fun of sending each of them one by one.\t0\n",
      "If you are Razr owner...you must have this!\t1\n",
      "Needless to say, I wasted my money.\t0\n",
      "What a waste of money and time!.\t0\n"
     ]
    }
   ],
   "source": [
    "!head \"./input/amazon_cells_labelled.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "387106cd-e89a-462f-b204-a91a73d12137",
    "_uuid": "cbd1a4b1d16ce7db6def7b3b393b48618d7e4777"
   },
   "source": [
    "# Tasks\n",
    "### 1. Read and concatenate data into test and train sets.\n",
    "### 2. Prepare the data for input into your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by loading in the data sets into their own dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_table('./input/amazon_cells_labelled.txt', header=None, names=[\"review\", \"sentiment\"])\n",
    "df_imdb = pd.read_table('./input/imdb_labelled.txt', header=None, names=[\"review\", \"sentiment\"])\n",
    "df_yelp = pd.read_table('./input/yelp_labelled.txt', header=None, names=[\"review\", \"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>I just got bored watching Jessice Lange take h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>Unfortunately, any virtue in this film's produ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>In a word, it is embarrassing.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>Exceptionally bad!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>All in all its an insult to one's intelligence...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>748 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  sentiment\n",
       "0    A very, very, very slow-moving, aimless movie ...          0\n",
       "1    Not sure who was more lost - the flat characte...          0\n",
       "2    Attempting artiness with black & white and cle...          0\n",
       "3         Very little music or anything to speak of.            0\n",
       "4    The best scene in the movie was when Gerardo i...          1\n",
       "..                                                 ...        ...\n",
       "743  I just got bored watching Jessice Lange take h...          0\n",
       "744  Unfortunately, any virtue in this film's produ...          0\n",
       "745                   In a word, it is embarrassing.            0\n",
       "746                               Exceptionally bad!            0\n",
       "747  All in all its an insult to one's intelligence...          0\n",
       "\n",
       "[748 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the IMDB and Yelp data as the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_imdb, df_yelp], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_imdb, df_yelp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a8240a39-7002-435b-ba45-ac859d209f7f",
    "_uuid": "69c6d7ea240a191abfaaf00574f09521944387d7"
   },
   "source": [
    "#### 2a: Find the ten most frequent words in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1748 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  sentiment\n",
       "0     A very, very, very slow-moving, aimless movie ...          0\n",
       "1     Not sure who was more lost - the flat characte...          0\n",
       "2     Attempting artiness with black & white and cle...          0\n",
       "3          Very little music or anything to speak of.            0\n",
       "4     The best scene in the movie was when Gerardo i...          1\n",
       "...                                                 ...        ...\n",
       "1743  I think food should have flavor and texture an...          0\n",
       "1744                           Appetite instantly gone.          0\n",
       "1745  Overall I was not impressed and would not go b...          0\n",
       "1746  The whole experience was underwhelming, and I ...          0\n",
       "1747  Then, as if I hadn't wasted enough of my life ...          0\n",
       "\n",
       "[1748 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>The screen does get smudged easily because it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>What a piece of junk.. I lose more calls on th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Item Does Not Match Picture.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The only thing that disappoint me is the infra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>You can not answer calls with the unit, never ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  sentiment\n",
       "0    So there is no way for me to plug it in here i...          0\n",
       "1                          Good case, Excellent value.          1\n",
       "2                               Great for the jawbone.          1\n",
       "3    Tied to charger for conversations lasting more...          0\n",
       "4                                    The mic is great.          1\n",
       "..                                                 ...        ...\n",
       "995  The screen does get smudged easily because it ...          0\n",
       "996  What a piece of junk.. I lose more calls on th...          0\n",
       "997                       Item Does Not Match Picture.          0\n",
       "998  The only thing that disappoint me is the infra...          0\n",
       "999  You can not answer calls with the unit, never ...          0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reviews_train = df_train.iloc[:, 0].values\n",
    "scores_train = df_train.iloc[:, 1].values\n",
    "\n",
    "reviews_test = df_test.iloc[:, 0].values\n",
    "scores_test = df_test.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A very, very, very slow-moving, aimless movie about a distressed, drifting young man.  '\n",
      " 'Not sure who was more lost - the flat characters or the audience, nearly half of whom walked out.  '\n",
      " 'Attempting artiness with black & white and clever camera angles, the movie disappointed - became even more ridiculous - as the acting was poor and the plot and lines almost non-existent.  '\n",
      " ... 'Overall I was not impressed and would not go back.'\n",
      " \"The whole experience was underwhelming, and I think we'll just go to Ninja Sushi next time.\"\n",
      " \"Then, as if I hadn't wasted enough of my life there, they poured salt in the wound by drawing out the time it took to bring the check.\"]\n"
     ]
    }
   ],
   "source": [
    "print(reviews_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_reviews_train = []\n",
    "\n",
    "for sentence in range(0, len(reviews_train)):\n",
    "    # Remove all the special characters\n",
    "    processed_review = re.sub(r'\\W', ' ', str(reviews_train[sentence]))\n",
    "\n",
    "    # remove all single characters\n",
    "    processed_review= re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_review)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    processed_review = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_review) \n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    processed_review = re.sub(r'\\s+', ' ', processed_review, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    processed_review = re.sub(r'^b\\s+', '', processed_review)\n",
    "\n",
    "    # Converting to Lowercase\n",
    "    processed_review = processed_review.lower()\n",
    "    \n",
    "    processed_reviews_train.append(processed_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_reviews_test = []\n",
    "\n",
    "for sentence in range(0, len(reviews_test)):\n",
    "    # Remove all the special characters\n",
    "    processed_review = re.sub(r'\\W', ' ', str(reviews_test[sentence]))\n",
    "\n",
    "    # remove all single characters\n",
    "    processed_review= re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_review)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    processed_review = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_review) \n",
    "\n",
    "    # Substituting multiple spaces with single space\n",
    "    processed_review = re.sub(r'\\s+', ' ', processed_review, flags=re.I)\n",
    "\n",
    "    # Removing prefixed 'b'\n",
    "    processed_review = re.sub(r'^b\\s+', '', processed_review)\n",
    "\n",
    "    # Converting to Lowercase\n",
    "    processed_review = processed_review.lower()\n",
    "    \n",
    "    processed_reviews_test.append(processed_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24683\n"
     ]
    }
   ],
   "source": [
    "review_words = []\n",
    "\n",
    "for sentence in processed_reviews_train:\n",
    "    processed_review = sentence.split()\n",
    "    for word in processed_review:\n",
    "        review_words.append(word)\n",
    "\n",
    "print(len(review_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 1434), ('and', 827), ('is', 511), ('of', 504), ('was', 481), ('it', 478), ('to', 473), ('this', 435), ('in', 312), ('i', 253)]\n"
     ]
    }
   ],
   "source": [
    "word_freq = Counter(review_words)\n",
    "common_words = word_freq.most_common(10)\n",
    "print(common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f4cc399e-66c4-4bf7-a8e1-03711372c7b4",
    "_uuid": "eb8b033dc4a841702ae52d4ec71e7718b3257dda"
   },
   "source": [
    "### 3. Train your model and justify your choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer (max_features=2500, min_df=7, max_df=0.8, stop_words=stopwords.words('english'))\n",
    "\n",
    "processed_reviews_train = vectorizer.fit_transform(processed_reviews_train)\n",
    "processed_reviews_test = vectorizer.transform(processed_reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = processed_reviews_train\n",
    "X_test = processed_reviews_test\n",
    "y_train = scores_train\n",
    "y_test = scores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200, random_state=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_classifier = RandomForestClassifier(n_estimators=200, random_state=0)\n",
    "text_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1a5840b2-c84c-42f6-9fc9-4fed64e48298",
    "_uuid": "f4eeecd64b54cc05098affe6cca4c40204af8ecf"
   },
   "source": [
    "### 4. Evaluate your model using metric(s) you see fit and justify your choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = text_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[399 101]\n",
      " [177 323]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.80      0.74       500\n",
      "           1       0.76      0.65      0.70       500\n",
      "\n",
      "    accuracy                           0.72      1000\n",
      "   macro avg       0.73      0.72      0.72      1000\n",
      "weighted avg       0.73      0.72      0.72      1000\n",
      "\n",
      "0.722\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
